{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2b60444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55100784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 모든 JSON 파일을 로드하고 content/date를 통일된 리스트로 합침\n",
    "def load_all_chunks(json_paths: List[str]) -> List[Dict[str, Any]]:\n",
    "    all_chunks = []\n",
    "    for path in json_paths:\n",
    "        with open(path, encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "            for item in data:\n",
    "                content = item.get(\"content\") or item.get(\"text\")\n",
    "                date = item.get(\"date\")\n",
    "                if content and date:\n",
    "                    all_chunks.append({\"content\": content, \"date\": date})\n",
    "    print(f\"[1] 총 청크 개수: {len(all_chunks)}\")\n",
    "    print(f\"[1] 예시 청크: {all_chunks[0] if all_chunks else '없음'}\")\n",
    "    assert all_chunks, \"청크가 비어있음\"\n",
    "    return all_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60874950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 날짜를 파싱해서 정렬에 쓸 수 있도록 변환\n",
    "def parse_date(date_str: str) -> datetime:\n",
    "    for fmt in (\"%Y.%m.%d\", \"%y.%m.%d\", \"%Y-%m-%d\"):\n",
    "        try:\n",
    "            return datetime.strptime(date_str, fmt)\n",
    "        except Exception:\n",
    "            continue\n",
    "    return datetime(1900, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b5dd1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 임베딩 모델 준비 (OpenAI API 사용)\n",
    "class OpenAIEmbedder:\n",
    "    def __init__(self, api_key, model=\"text-embedding-3-large\"):\n",
    "        self.api_key = api_key\n",
    "        self.model = model\n",
    "\n",
    "    def encode(self, texts, show_progress_bar=False, convert_to_numpy=True):\n",
    "        openai.api_key = self.api_key  # 항상 최신 키로 할당\n",
    "        embeddings = []\n",
    "        for text in texts:\n",
    "            response = openai.embeddings.create(\n",
    "                input=text,\n",
    "                model=self.model\n",
    "            )\n",
    "            emb = response.data[0].embedding\n",
    "            embeddings.append(emb)\n",
    "        if convert_to_numpy:\n",
    "            import numpy as np\n",
    "            return np.array(embeddings)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "814f6a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제 API 키를 환경변수에서 불러오기\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "embedder = OpenAIEmbedder(api_key=api_key, model=\"text-embedding-3-large\")\n",
    "\n",
    "import faiss\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 모든 청크 임베딩 및 FAISS 벡터스토어 구축\n",
    "def build_faiss_index(chunks: List[Dict[str, Any]]):\n",
    "    texts = [c[\"content\"] for c in chunks]\n",
    "    metadatas = [{\"date\": c[\"date\"]} for c in chunks]\n",
    "    embeddings = embedder.encode(texts, show_progress_bar=True, convert_to_numpy=True)\n",
    "    print(f\"[2] 임베딩 shape: {embeddings.shape}\")\n",
    "    assert embeddings.shape[0] == len(texts), \"임베딩 개수 불일치\"\n",
    "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "    index.add(embeddings)\n",
    "    print(f\"[3] FAISS 인덱스 벡터 개수: {index.ntotal}\")\n",
    "    assert index.ntotal == len(texts), \"FAISS 인덱스 개수 불일치\"\n",
    "    return index, embeddings, texts, metadatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68a57b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 쿼리 임베딩 후 FAISS로 유사 청크 top-k 검색\n",
    "def search_faiss(query: str, index, embeddings, texts, metadatas, top_k=5):\n",
    "    q_emb = embedder.encode([query], convert_to_numpy=True)  # 수정된 부분\n",
    "    D, I = index.search(q_emb, top_k)\n",
    "    results = []\n",
    "    for idx in I[0]:\n",
    "        if idx < len(texts):\n",
    "            results.append({\n",
    "                \"content\": texts[idx],\n",
    "                \"date\": metadatas[idx][\"date\"],\n",
    "                \"parsed_date\": parse_date(metadatas[idx][\"date\"])\n",
    "            })\n",
    "    results = sorted(results, key=lambda x: x[\"parsed_date\"], reverse=True)\n",
    "    print(f\"[4] 쿼리 '{query}' top-{top_k} 검색 결과:\")\n",
    "    for r in results:\n",
    "        print(f\"  - [{r['date']}] {r['content'][:40]}...\")\n",
    "    assert results, \"검색 결과 없음\"\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26838086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. LLM 준비 (OpenAI API 키 필요)\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.2,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    openai_api_key=api_key\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc351d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. 챗봇 히스토리 관리 및 답변 생성\n",
    "class CBAMChatbot:\n",
    "    def __init__(self, index, embeddings, texts, metadatas):\n",
    "        self.index = index\n",
    "        self.embeddings = embeddings\n",
    "        self.texts = texts\n",
    "        self.metadatas = metadatas\n",
    "        self.history = []\n",
    "    \n",
    "    def ask(self, user_query: str):\n",
    "        relevant_chunks = search_faiss(user_query, self.index, self.embeddings, self.texts, self.metadatas, top_k=5)\n",
    "        context = \"\\n\\n\".join([f\"[{c['date']}] {c['content']}\" for c in relevant_chunks])\n",
    "        history_prompt = \"\"\n",
    "        for u, b in self.history[-5:]:\n",
    "            history_prompt += f\"User: {u}\\nBot: {b}\\n\"\n",
    "        prompt = (\n",
    "            f\"{history_prompt}\"\n",
    "            f\"User: {user_query}\\n\"\n",
    "            f\"CBAM 관련 최신 정보와 문서를 참고하여 답변해 주세요.\\n\"\n",
    "            f\"참고 문서:\\n{context}\\n\"\n",
    "            f\"Bot:\"\n",
    "        )\n",
    "        # 프롬프트를 HumanMessage 형식으로 변환\n",
    "        messages = [HumanMessage(content=prompt)]\n",
    "        # invoke 메서드 사용\n",
    "        answer = llm.invoke(messages)\n",
    "        print(f\"[5] LLM 답변: {answer[:100]}...\")\n",
    "        self.history.append((user_query, answer))\n",
    "        return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e53ac5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 총 청크 개수: 111\n",
      "[1] 예시 청크: {'content': '구조\\n개념 요약 : 해당 항목이 CBAM 제도 상 어떤 의미를 가지는지 간단히 정의\\n플랫폼 반영 방식 : 실제 우리 플랫폼에서 그 개념이 어떻게 구현되었는지 설명\\n보충 설명 : 실무자가 이해할 수 있도록 배경이나 예시 중심으로 풀어 설명', 'date': '23.08.17'}\n",
      "[2] 임베딩 shape: (111, 3072)\n",
      "[3] FAISS 인덱스 벡터 개수: 111\n",
      "[4] 쿼리 '전구물질이 뭐야?' top-5 검색 결과:\n",
      "  - [2025.02.26] 제조건이 되거나 이를 배제해서는 안 된다.자료: COM(2025)81(E...\n",
      "  - [2025.02.26] 우리 정부의 탄소중립 정책도 산업 발전을 목표로 새롭게 설계될 필요가 있...\n",
      "  - [23.08.17] 전구물질 배출량 산정 방법\n",
      "개념 요약 : 옴니버스 패키지 발표 내용에 따...\n",
      "  - [23.08.17] 단순재/복합재 여부 확인\n",
      "개념 요약 : 전구물질 포함 여부에 따라 단순/...\n",
      "  - [23.08.17] 생산공정 내 투입물질 확인\n",
      "개념 요약 : 직접 배출량 산정을 위해 투입 ...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'AIMessage' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# 사용자 입력을 받아 질문 처리\u001b[39;00m\n\u001b[32m     14\u001b[39m user_input = \u001b[38;5;28minput\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m질문을 입력하세요: \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m answer = \u001b[43mchatbot\u001b[49m\u001b[43m.\u001b[49m\u001b[43mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m답변:\u001b[39m\u001b[33m\"\u001b[39m, answer)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mCBAMChatbot.ask\u001b[39m\u001b[34m(self, user_query)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# invoke 메서드 사용\u001b[39;00m\n\u001b[32m     26\u001b[39m answer = llm.invoke(messages)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[5] LLM 답변: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43manswer\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     28\u001b[39m \u001b[38;5;28mself\u001b[39m.history.append((user_query, answer))\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m answer\n",
      "\u001b[31mTypeError\u001b[39m: 'AIMessage' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# 8. 전체 파이프라인 실행 예시\n",
    "if __name__ == \"__main__\":\n",
    "    json_paths = [\n",
    "        r\"C:\\bit_esg\\python\\LLM--main\\cbam_chunk.json\",\n",
    "        r\"C:\\bit_esg\\python\\LLM--main\\gl_chunk.json\",\n",
    "        r\"C:\\bit_esg\\python\\LLM--main\\manual_chunk.json\",\n",
    "        r\"C:\\bit_esg\\python\\LLM--main\\omnibus_chunk.json\"\n",
    "    ]\n",
    "    all_chunks = load_all_chunks(json_paths)\n",
    "    index, embeddings, texts, metadatas = build_faiss_index(all_chunks)\n",
    "    chatbot = CBAMChatbot(index, embeddings, texts, metadatas)\n",
    "\n",
    "    # 사용자 입력을 받아 질문 처리\n",
    "    user_input = input(\"질문을 입력하세요: \")\n",
    "    answer = chatbot.ask(user_input)\n",
    "    print(\"답변:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8e1d69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4005eea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36809837",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
