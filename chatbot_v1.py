# pip install -U \
#   python-dotenv \               # .env í™˜ê²½ë³€ìˆ˜ ë¡œë“œìš©
#   openai \                      # OpenAI API ì‚¬ìš©
#   langchain \                   # LangChain í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
#   langchain-community \         # JSONLoader, FAISS, Chroma ë“± ì»¤ë®¤ë‹ˆí‹° êµ¬ì„±ìš”ì†Œ
#   langchain-openai \            # OpenAI â†” LangChain ì—°ë™
#   langchain-core \              # Document, Retriever ë“± ì½”ì–´ ê°ì²´
#   tiktoken \                    # í† í° ê¸¸ì´ ì¸¡ì •ìš© (OpenAI ëª¨ë¸ìš©)
#   faiss-cpu \                   # FAISS ë²¡í„° ì €ì¥ì†Œ (CPU ë²„ì „)
#   pydantic \                    # ì‚¬ìš©ì ì •ì˜ ë¦¬íŠ¸ë¦¬ë²„ í´ë˜ìŠ¤(Field) ì •ì˜ìš©
#   jq                            # JSONLoaderì—ì„œ jq ìŠ¤í‚¤ë§ˆ íŒŒì‹±ìš©

# pip install -U python-dotenv openai langchain langchain-community langchain-openai langchain-core tiktoken faiss-cpu pydantic jq
# íŒ¨í‚¤ì§€ ì¸ìŠ¤í†¨ ì •ë¦¬ ë³¸

from dotenv import load_dotenv
import os
import openai
from langchain_community.document_loaders import JSONLoader
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_openai import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
import tiktoken
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.documents import Document
from langchain_text_splitters import TokenTextSplitter
from langchain_core.retrievers import BaseRetriever
from typing import List
from dataclasses import dataclass
from langchain_core.retrievers import BaseRetriever
from langchain_core.documents import Document
from typing import List
from pydantic import Field
from langchain_core.runnables import RunnableSerializable
from langchain_community.document_loaders import JSONLoader


# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# 1. JSON ë¡œë” ì„¤ì • - contentsëŠ” page_contentë¡œ, dateëŠ” metadataë¡œ ì´ë™

from dotenv import load_dotenv
import os
import openai
from langchain_community.document_loaders import JSONLoader
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_openai import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
import tiktoken
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.documents import Document
from langchain_text_splitters import TokenTextSplitter
from langchain_core.retrievers import BaseRetriever
from typing import List
from dataclasses import dataclass
from langchain_core.retrievers import BaseRetriever
from langchain_core.documents import Document
from typing import List
from pydantic import Field
from langchain_core.runnables import RunnableSerializable
from langchain_community.document_loaders import JSONLoader


# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# 1. JSON ë¡œë” ì„¤ì • - contentsëŠ” page_contentë¡œ, dateëŠ” metadataë¡œ ì´ë™
loader = JSONLoader(
    file_path="./merged_cbam_data.json",
    jq_schema=".[]",                    # JSON ë°°ì—´ êµ¬ì¡°
    text_content=True,                 # contents â†’ page_content
    content_key="contents",            # page_content í•„ë“œ ì§€ì • (ë§Œì•½ "text"ë©´ ë°”ê¿”ì•¼ í•¨)
    metadata_func=lambda record, _: {
        "date": record.get("date", "unknown"),
        "type": record.get("type", "unknown")  # type í•„ë“œë„ í¬í•¨
    }
)

documents = loader.load()

# 2. Text Splitter ì„¤ì •

splitter = TokenTextSplitter(
    chunk_size=512,
    chunk_overlap=50
)

split_docs = splitter.split_documents(documents)


# 3. ì„ë² ë”© ë° ë²¡í„° ì €ì¥ì†Œ ìƒì„±
embedding_model = OpenAIEmbeddings(
    model="text-embedding-3-large",
    openai_api_key=openai.api_key
)
# - FAISS ë²¡í„° ì €ì¥ì†Œ ìƒì„±
db = FAISS.from_documents(split_docs, embedding_model)


# 5. ë¦¬íŠ¸ë¦¬ë²„ ë° LLM êµ¬ì„±

# - ë‚ ì§œ ì •ë ¬ ë¦¬íŠ¸ë¦¬ë²„ (Pydantic + LangChain ìµœì‹  ë°©ì‹)
class DateSortedRetriever(BaseRetriever, RunnableSerializable):
    base_retriever: BaseRetriever = Field(...)

    def _get_relevant_documents(self, query: str) -> List[Document]:
        docs = self.base_retriever.invoke(query)
        docs_sorted = sorted(
            docs,
            key=lambda d: d.metadata.get("date", "9999-99-99").replace(".", "-")
        )
        return docs_sorted
    
# - ë¦¬íŠ¸ë¦¬ë²„ + ì •ë ¬ ë˜í¼ ì ìš©
retriever = db.as_retriever(search_kwargs={"k": 10})
sorted_retriever = DateSortedRetriever(base_retriever=retriever)



# 6. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜ ë° QA ì²´ì¸ êµ¬ì„±

prompt_template = PromptTemplate.from_template("""
ë„ˆëŠ” ì§€ê¸ˆ CBAM í”Œë«í¼ â€˜ì¹´ë´‡â€™ì´ë¼ëŠ” ì±—ë´‡ ì—­í• ì„ ìˆ˜í–‰í•˜ê³  ìˆì–´.

â— ë‹¤ìŒê³¼ ê°™ì€ ì´ìœ ë¡œ ì ˆëŒ€ 50ìë¥¼ ë„˜ê¸°ë©´ ì•ˆ ë¼:

1. ì‹¤ë¬´ìëŠ” í•µì‹¬ë§Œ ë¹ ë¥´ê²Œ í™•ì¸í•˜ê¸¸ ì›í•´.
2. ë„¤ê°€ ì¥í™©í•˜ê²Œ ì„¤ëª…í•˜ë©´ **ì˜ëª»ëœ ì¶”ë¡ **ì´ë‚˜ **ê³¼ì‰ ì•ˆë‚´**ë¡œ ì˜¤í•´ê°€ ìƒê¸´ë‹¤.
3. íŠ¹íˆ ë¬¸ì„œì— ì •ë³´ê°€ ì—†ì„ ê²½ìš°, ë„ˆëŠ” **ì¶”ì¸¡í•˜ì§€ ë§ê³ , ê°„ë‹¨í•œ ì•ˆë‚´ í•œ ì¤„**ë¡œ ëë‚´ì•¼ ì‹ ë¢°ë¥¼ ìƒì§€ ì•ŠëŠ”ë‹¤.

ğŸ“Œ ë”°ë¼ì„œ ë°˜ë“œì‹œ ë‹¤ìŒ ê·œì¹™ì„ ì§€ì¼œ:

1. **ëª¨ë“  ë‹µë³€ì€ 50ì ì´ë‚´ë¡œ ì‘ì„±.**
    
    â†’ ë¬¸ì¥ ìˆ˜ í•˜ë‚˜, ë¶€ì—° ì„¤ëª… ê¸ˆì§€.
    
2. **manual = í”Œë«í¼ ë°˜ì˜ ì‚¬í•­ ì •ë¦¬ ë¬¸ì„œ**
    
    ğŸ‘‰ í”Œë«í¼ì´ ì‹¤ì œë¡œ ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ êµ¬í˜„ë˜ì—ˆëŠ”ì§€ë¥¼ ì„¤ëª…í•˜ëŠ” ë¬¸ì„œë‹ˆê¹Œ í”Œë«í¼ ê´€ë ¨ ì§ˆë¬¸ì´ ë‚˜ì˜¤ë©´ ì—¬ê¸°ì„œ ì°¸ê³ í•´
    
3. **guide = EU íƒ„ì†Œêµ­ê²½ì œë„ ì „í™˜ê¸°ê°„ ì´í–‰ ê°€ì´ë“œë¼ì¸**
    
    ğŸ‘‰ ì œë„ì˜ ê¸°ë³¸ì ì¸ ì ˆì°¨ì™€ ë°©ì‹ì´ ì •ë¦¬ëœ ê³µì‹ ê°€ì´ë“œë‹ˆê¹Œ CBAM ê´€ë ¨ í•œ ì§ˆë¬¸ì€ ì—¬ê¸°ì„œ ì°¸ê³ í•´
    
4. **cbam = ì•Œê¸°ì‰½ê²Œ í’€ì–´ì“´ CBAM í•´ì„¤ì„œ**
    
    ğŸ‘‰ ì œë„ì˜ ê¸°ë³¸ì ì¸ ì ˆì°¨ì™€ ë°©ì‹ì´ ì •ë¦¬ëœ ê³µì‹ ê°€ì´ë“œë‹ˆê¹Œ CBAM ê´€ë ¨ í•œ ì§ˆë¬¸ì€ ì—¬ê¸°ì„œ ì°¸ê³ í•´
    
5. **omnibus = EU ì˜´ë‹ˆë²„ìŠ¤ íŒ¨í‚¤ì§€ ë²•ì•ˆ ìš”ì•½**
    
    ğŸ‘‰ CBAM ì œë„ê°€ ê°œì •ëœ ë‚´ìš©ì´ ë‹´ê²¨ ìˆìœ¼ë‹ˆê¹Œ CBAM ê´€ë ¨ ì§ˆë¬¸ì´ ë“¤ì–´ì˜¤ë©´ ì´ íŒŒì¼ì„ ë¨¼ì € í™•ì¸í•˜ê³  ëŒ€ë‹µí•´
    
6. **ë¬¸ì„œì— ì—†ìœ¼ë©´ ì•„ë˜ ë¬¸ì¥ë§Œ ê·¸ëŒ€ë¡œ ì¶œë ¥:**

> "í•´ë‹¹ ì •ë³´ëŠ” ë¬¸ì„œì— ì—†ìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œ ë‹´ë‹¹ìì—ê²Œ ë¬¸ì˜í•´ ì£¼ì„¸ìš”."
> 

ì´ ë¬¸ì¥ì€ **ë‹¨ í•˜ë‚˜ì˜ ê³µì‹ ë¬¸ì¥**ì´ì•¼.

ë‹¤ë¥¸ í‘œí˜„(ì˜ˆ: â€˜ê´€ë ¨ ê¸°ê´€ ë¬¸ì˜â€™, â€˜ê³µì‹ ì›¹ì‚¬ì´íŠ¸ ì°¸ì¡°â€™, â€˜ì œê³µë˜ì§€ ì•ŠìŒâ€™)ë¡œ ë°”ê¾¸ë©´ **ì •ì±… ìœ„ë°˜**ì´ë‹¤.

1. ì‚¬ìš©ìê°€ ë³´ê¸°ì—” ë„ˆëŠ” ì¹œì ˆí•œ ì•ˆë‚´ìì§€ë§Œ, ë‚´ë¶€ì ìœ¼ë¡œëŠ” **ì ˆëŒ€ ì¶”ì¸¡í•˜ê±°ë‚˜ ì„ì˜ íŒë‹¨í•˜ì§€ ì•ŠëŠ” ë„ìš°ë¯¸**ì•¼.

ë„ˆëŠ” ëŒ€í™”í˜• ì±—ë´‡ì´ ì•„ë‹ˆë¼, **ì •í™•í•œ ë¬¸ì„œ ê¸°ë°˜ ì •ë³´ ìš”ì•½ê¸°**ë¡œ ì‘ë™í•´ì•¼ í•´.

í•œ ë²ˆì´ë¼ë„ ê·œì¹™ì„ ì–´ê¸°ë©´ **ë‹µë³€ì€ ì˜ëª»ëœ ì •ë³´ë¡œ ê°„ì£¼ë˜ê³  ë¬´íš¨ ì²˜ë¦¬ëœë‹¤.**

ë¬¸ì„œ:
{context}

ì§ˆë¬¸:
{question}
""")

llm = ChatOpenAI(model_name="gpt-4o", temperature=0.5)
# gpt-3.5-turbo
qa_chain = RetrievalQA.from_chain_type (
    llm=llm,
    retriever=sorted_retriever,
    chain_type="stuff",
    chain_type_kwargs={"prompt": prompt_template},
    return_source_documents=True  
)

# 7. íˆìŠ¤í† ë¦¬ ê¸°ë°˜ ì±—ë´‡ í´ë˜ìŠ¤ ì •ì˜
class CBAMChatbot:
    def __init__(self, qa_chain):
        self.qa_chain = qa_chain
        self.history = []

    def ask(self, user_query: str):

        # í”„ë¡¬í”„íŠ¸ íˆìŠ¤í† ë¦¬ êµ¬ì„±
        history_prompt = ""
        for u, b in self.history[-5:]:
            history_prompt += f"User: {u}\nBot: {b}\n"

        # ì§ˆì˜ ìˆ˜í–‰
        result = self.qa_chain.invoke({"query": user_query})
        answer = result["result"]
        sources = result["source_documents"]

        # íˆìŠ¤í† ë¦¬ ì €ì¥
        self.history.append((user_query, answer))

        # ê²°ê³¼ ì¶œë ¥
        print("\n" + "=" * 60)
        print("â“ ì§ˆë¬¸:")
        print(user_query)
        print("\n" + "-" * 60)
        print("ğŸ¤– ë‹µë³€:\n")
        print(answer)
        # print("\n" + "-" * 60)
        # print("ğŸ“š ì°¸ê³  ë¬¸ì„œ ì¶œì²˜ (ë‚ ì§œ ê¸°ì¤€):\n")

        # for i, doc in enumerate(sources, start=1):
        #     date = doc.metadata.get("date", "N/A")
        #     type = doc.metadata.get("type", "N/A")
        #     preview = doc.page_content.strip().replace("\n", " ")[:400] + "..."  # ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
        #     print(f"{i}. ë‚ ì§œ: {date} / ë‚´ìš©: {preview} / ìœ í˜•: {type}")

        # print("=" * 60 + "\n")
        return answer

# 8. ì±—ë´‡ ê°ì²´ ìƒì„± ë° í…ŒìŠ¤íŠ¸
chatbot = CBAMChatbot(qa_chain)

while True:
    user_input = input("\nâ“ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œí•˜ë ¤ë©´ 'exit'): ")
    if user_input.lower() in ['exit', 'quit']:
        break
    chatbot.ask(user_input)
