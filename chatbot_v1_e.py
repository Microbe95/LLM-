from datasets import Dataset
from dotenv import load_dotenv
import os
import openai
import pandas as pd
from langchain_community.document_loaders import JSONLoader
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain_text_splitters import TokenTextSplitter
from langchain_core.retrievers import BaseRetriever
from langchain_core.documents import Document
from pydantic import Field
from langchain_core.runnables import RunnableSerializable
from ragas.metrics import (
    faithfulness,
    answer_relevancy,
    context_precision,
    context_recall,
    # context_entities_recall,
)
from ragas import evaluate

from typing import List

# --------------------- 1. í™˜ê²½ ì„¤ì • ---------------------
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# --------------------- 2. ë¬¸ì„œ ë¡œë”© ë° ë¶„í•  ---------------------
# 1. JSON ë¡œë” ì„¤ì • - contentsëŠ” page_contentë¡œ, dateëŠ” metadataë¡œ ì´ë™
loader = JSONLoader(
    file_path="./merged_cbam_data.json",
    jq_schema=".[]",                    # JSON ë°°ì—´ êµ¬ì¡°
    text_content=True,                 # contents â†’ page_content
    content_key="contents",            # page_content í•„ë“œ ì§€ì • (ë§Œì•½ "text"ë©´ ë°”ê¿”ì•¼ í•¨)
    metadata_func=lambda record, _: {
        "date": record.get("date", "unknown"),
        "type": record.get("type", "unknown")  # type í•„ë“œë„ í¬í•¨
    }
)

documents = loader.load()
# 2. Text Splitter ì„¤ì •
from langchain_text_splitters import TokenTextSplitter

splitter = TokenTextSplitter(chunk_size=512, chunk_overlap=50)
split_docs = splitter.split_documents(documents)

# --------------------- 3. ë²¡í„° ì €ì¥ì†Œ ---------------------
embedding_model = OpenAIEmbeddings(
    model="text-embedding-3-large",
    openai_api_key=openai.api_key
)
db = FAISS.from_documents(split_docs, embedding_model)

# --------------------- 4. ë¦¬íŠ¸ë¦¬ë²„ êµ¬ì„± ---------------------
class DateSortedRetriever(BaseRetriever, RunnableSerializable):
    base_retriever: BaseRetriever = Field(...)

    def _get_relevant_documents(self, query: str) -> List[Document]:
        docs = self.base_retriever.invoke(query)
        docs_sorted = sorted(
            docs,
            key=lambda d: d.metadata.get("date", "9999-99-99").replace(".", "-")
        )
        return docs_sorted

retriever = db.as_retriever(search_kwargs={"k": 10})
sorted_retriever = DateSortedRetriever(base_retriever=retriever)

# --------------------- 5. í”„ë¡¬í”„íŠ¸ ë° QA ì²´ì¸ ---------------------
prompt_template = PromptTemplate.from_template("""
ë„ˆëŠ” ì§€ê¸ˆ CBAM í”Œë«í¼ â€˜ì¹´ë´‡â€™ì´ë¼ëŠ” ì±—ë´‡ ì—­í• ì„ ìˆ˜í–‰í•˜ê³  ìˆì–´.

â— ë‹¤ìŒê³¼ ê°™ì€ ì´ìœ ë¡œ ì ˆëŒ€ 50ìë¥¼ ë„˜ê¸°ë©´ ì•ˆ ë¼:

1. ì‹¤ë¬´ìëŠ” í•µì‹¬ë§Œ ë¹ ë¥´ê²Œ í™•ì¸í•˜ê¸¸ ì›í•´.
2. ë„¤ê°€ ì¥í™©í•˜ê²Œ ì„¤ëª…í•˜ë©´ **ì˜ëª»ëœ ì¶”ë¡ **ì´ë‚˜ **ê³¼ì‰ ì•ˆë‚´**ë¡œ ì˜¤í•´ê°€ ìƒê¸´ë‹¤.
3. íŠ¹íˆ ë¬¸ì„œì— ì •ë³´ê°€ ì—†ì„ ê²½ìš°, ë„ˆëŠ” **ì¶”ì¸¡í•˜ì§€ ë§ê³ , ê°„ë‹¨í•œ ì•ˆë‚´ í•œ ì¤„**ë¡œ ëë‚´ì•¼ ì‹ ë¢°ë¥¼ ìƒì§€ ì•ŠëŠ”ë‹¤.

ğŸ“Œ ë”°ë¼ì„œ ë°˜ë“œì‹œ ë‹¤ìŒ ê·œì¹™ì„ ì§€ì¼œ:

1. **ëª¨ë“  ë‹µë³€ì€ 50ì ì´ë‚´ë¡œ ì‘ì„±.**
    
    â†’ ë¬¸ì¥ ìˆ˜ í•˜ë‚˜, ë¶€ì—° ì„¤ëª… ê¸ˆì§€.
    
2. **manual = í”Œë«í¼ ë°˜ì˜ ì‚¬í•­ ì •ë¦¬ ë¬¸ì„œ**
    
    ğŸ‘‰ í”Œë«í¼ì´ ì‹¤ì œë¡œ ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ êµ¬í˜„ë˜ì—ˆëŠ”ì§€ë¥¼ ì„¤ëª…í•˜ëŠ” ë¬¸ì„œë‹ˆê¹Œ í”Œë«í¼ ê´€ë ¨ ì§ˆë¬¸ì´ ë‚˜ì˜¤ë©´ ì—¬ê¸°ì„œ ì°¸ê³ í•´
    
3. **guide = EU íƒ„ì†Œêµ­ê²½ì œë„ ì „í™˜ê¸°ê°„ ì´í–‰ ê°€ì´ë“œë¼ì¸**
    
    ğŸ‘‰ ì œë„ì˜ ê¸°ë³¸ì ì¸ ì ˆì°¨ì™€ ë°©ì‹ì´ ì •ë¦¬ëœ ê³µì‹ ê°€ì´ë“œë‹ˆê¹Œ CBAM ê´€ë ¨ í•œ ì§ˆë¬¸ì€ ì—¬ê¸°ì„œ ì°¸ê³ í•´
    
4. **cbam = ì•Œê¸°ì‰½ê²Œ í’€ì–´ì“´ CBAM í•´ì„¤ì„œ**
    
    ğŸ‘‰ ì œë„ì˜ ê¸°ë³¸ì ì¸ ì ˆì°¨ì™€ ë°©ì‹ì´ ì •ë¦¬ëœ ê³µì‹ ê°€ì´ë“œë‹ˆê¹Œ CBAM ê´€ë ¨ í•œ ì§ˆë¬¸ì€ ì—¬ê¸°ì„œ ì°¸ê³ í•´
    
5. **omnibus = EU ì˜´ë‹ˆë²„ìŠ¤ íŒ¨í‚¤ì§€ ë²•ì•ˆ ìš”ì•½**
    
    ğŸ‘‰ CBAM ì œë„ê°€ ê°œì •ëœ ë‚´ìš©ì´ ë‹´ê²¨ ìˆìœ¼ë‹ˆê¹Œ CBAM ê´€ë ¨ ì§ˆë¬¸ì´ ë“¤ì–´ì˜¤ë©´ ì´ íŒŒì¼ì„ ë¨¼ì € í™•ì¸í•˜ê³  ëŒ€ë‹µí•´
    
6. **ë¬¸ì„œì— ì—†ìœ¼ë©´ ì•„ë˜ ë¬¸ì¥ë§Œ ê·¸ëŒ€ë¡œ ì¶œë ¥:**

> "í•´ë‹¹ ì •ë³´ëŠ” ë¬¸ì„œì— ì—†ìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œ ë‹´ë‹¹ìì—ê²Œ ë¬¸ì˜í•´ ì£¼ì„¸ìš”."
> 

ì´ ë¬¸ì¥ì€ **ë‹¨ í•˜ë‚˜ì˜ ê³µì‹ ë¬¸ì¥**ì´ì•¼.

ë‹¤ë¥¸ í‘œí˜„(ì˜ˆ: â€˜ê´€ë ¨ ê¸°ê´€ ë¬¸ì˜â€™, â€˜ê³µì‹ ì›¹ì‚¬ì´íŠ¸ ì°¸ì¡°â€™, â€˜ì œê³µë˜ì§€ ì•ŠìŒâ€™)ë¡œ ë°”ê¾¸ë©´ **ì •ì±… ìœ„ë°˜**ì´ë‹¤.

1. ì‚¬ìš©ìê°€ ë³´ê¸°ì—” ë„ˆëŠ” ì¹œì ˆí•œ ì•ˆë‚´ìì§€ë§Œ, ë‚´ë¶€ì ìœ¼ë¡œëŠ” **ì ˆëŒ€ ì¶”ì¸¡í•˜ê±°ë‚˜ ì„ì˜ íŒë‹¨í•˜ì§€ ì•ŠëŠ” ë„ìš°ë¯¸**ì•¼.

ë„ˆëŠ” ëŒ€í™”í˜• ì±—ë´‡ì´ ì•„ë‹ˆë¼, **ì •í™•í•œ ë¬¸ì„œ ê¸°ë°˜ ì •ë³´ ìš”ì•½ê¸°**ë¡œ ì‘ë™í•´ì•¼ í•´.

í•œ ë²ˆì´ë¼ë„ ê·œì¹™ì„ ì–´ê¸°ë©´ **ë‹µë³€ì€ ì˜ëª»ëœ ì •ë³´ë¡œ ê°„ì£¼ë˜ê³  ë¬´íš¨ ì²˜ë¦¬ëœë‹¤.**

ë¬¸ì„œ:
{context}

ì§ˆë¬¸:
{question}
""")

llm = ChatOpenAI(model_name="gpt-4o", temperature=0.5)

qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=sorted_retriever,
    chain_type="stuff",
    chain_type_kwargs={"prompt": prompt_template},
    return_source_documents=True
)

# --------------------- 6. ì±—ë´‡ í´ë˜ìŠ¤ ---------------------
class CBAMChatbot:
    def __init__(self, qa_chain):
        self.qa_chain = qa_chain
        self.history = []

    def ask(self, user_query: str):

        # í”„ë¡¬í”„íŠ¸ íˆìŠ¤í† ë¦¬ êµ¬ì„±
        history_prompt = ""
        for u, b in self.history[-5:]:
            history_prompt += f"User: {u}\nBot: {b}\n"

        # ì§ˆì˜ ìˆ˜í–‰
        result = self.qa_chain.invoke({"query": user_query})
        answer = result["result"]   
        sources = result["source_documents"]    

        # íˆìŠ¤í† ë¦¬ ì €ì¥
        self.history.append((user_query, answer))
# class CBAMChatbot:
#     def __init__(self, qa_chain):
#         self.qa_chain = qa_chain
#         self.history = []

#     def ask(self, user_query: str):
#         result = self.qa_chain.invoke({"query": user_query})
#         answer = result["result"]
#         sources = result["source_documents"]
#         self.history.append((user_query, answer))
#         return {
#             "answer": answer,
#             "sources": [
#                 {
#                     "date": doc.metadata.get("date", "N/A"),
#                     "preview": doc.page_content[:]
#                 }
#                 for doc in sources
#             ]
#         }

chatbot = CBAMChatbot(qa_chain)

# --------------------- 7. ì§ˆë¬¸ ë¡œë”© ---------------------
import pandas as pd
question_df = pd.read_excel("Q-list.xlsx", header=2)
questions = [q for q in question_df["Unnamed: 3"].dropna().tolist() if q != "ì§ˆë¬¸"]
# ì •ë‹µ ì¶”ì¶œ (ìˆ«ì, ì´ìƒí•œ ê°’ ì œì™¸)
ground_truths = [
    g for g in question_df["Unnamed: 7"]
    if pd.notna(g)
    and isinstance(g, str)  # ë¬¸ìì—´ë§Œ í—ˆìš©
    and len(g.strip()) > 5  # ë„ˆë¬´ ì§§ì€ ê±´ ì œì™¸
    and g.strip() != "ëŒ€ë‹µ"
]
# --------------------- 8. RAGAS í‰ê°€ìš© ë°ì´í„°ì…‹ ìƒì„± ---------------------
samples = []
for q, g in zip(questions, ground_truths):
    response = chatbot.ask(q)
    samples.append({
        "question": q,
        "answer": response["answer"],
        "contexts": [ctx["preview"] for ctx in response["sources"]],
        "ground_truth": g   # âœ… ì—¬ê¸°ì— ì‹¤ì œ ì •ë‹µ ì…ë ¥
    })

ragas_dataset = Dataset.from_list(samples)

# --------------------- 9. RAGAS ì§ˆë¬¸ë³„ í‰ê°€ ì‹¤í–‰ ---------------------
from ragas import SingleTurnSample, EvaluationDataset

for idx, sample_dict in enumerate(samples):
    sample = SingleTurnSample(
        user_input=sample_dict["question"],
        retrieved_contexts=sample_dict["contexts"],
        response=sample_dict["answer"],
        reference=sample_dict["ground_truth"]
    )
    dataset = EvaluationDataset(samples=[sample])
    result = evaluate(
        dataset,
        metrics=[faithfulness, answer_relevancy, context_precision, context_recall]
    )
    print(f"\nğŸ” Q{idx+1}: {sample.user_input}")
    print(f"ğŸ’¬ ì±—ë´‡ ì‘ë‹µ: {sample.response}")
    print(result)

