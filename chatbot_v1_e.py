from datasets import Dataset
from dotenv import load_dotenv
import os
import openai
import pandas as pd
from langchain_community.document_loaders import JSONLoader
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain_text_splitters import TokenTextSplitter
from langchain_core.retrievers import BaseRetriever
from langchain_core.documents import Document
from pydantic import Field
from langchain_core.runnables import RunnableSerializable
from ragas.metrics import (
    faithfulness,
    answer_relevancy,
    context_precision,
    context_recall,
    # context_entities_recall,
)
from langchain.retrievers.multi_query import MultiQueryRetriever
from langchain_openai import ChatOpenAI
from ragas import evaluate
from langchain_text_splitters import TokenTextSplitter
from typing import List

# --------------------- 1. í™˜ê²½ ì„¤ì • ---------------------
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# --------------------- 2. ë¬¸ì„œ ë¡œë”© ë° ë¶„í•  ---------------------
# 1. JSON ë¡œë” ì„¤ì • - contentsëŠ” page_contentë¡œ, dateëŠ” metadataë¡œ ì´ë™
loader = JSONLoader(
    file_path="./merged_cbam_data.json",
    jq_schema=".[]",                    # JSON ë°°ì—´ êµ¬ì¡°
    text_content=True,                 # contents â†’ page_content
    content_key="contents",            # page_content í•„ë“œ ì§€ì • (ë§Œì•½ "text"ë©´ ë°”ê¿”ì•¼ í•¨)
    metadata_func=lambda record, _: {
        "date": record.get("date", "unknown"),
        "type": record.get("type", "unknown")  # type í•„ë“œë„ í¬í•¨
    }
)

documents = loader.load()

# ---------------------3. Text Splitter ì„¤ì •  ---------------------


splitter = TokenTextSplitter(
    chunk_size=512, 
    chunk_overlap=50)

split_docs = splitter.split_documents(documents)


# ---------------------4. ì„ë² ë”© ë° ë²¡í„° ì €ì¥ì†Œ ìƒì„± --------------------- #

# ì„ë² ë”© ëª¨ë¸ ìƒì„±
embedding_model = OpenAIEmbeddings(
    model="text-embedding-3-large",
    openai_api_key=openai.api_key
)

# FAISS ë²¡í„° ì €ì¥ì†Œ ìƒì„±
db = FAISS.from_documents(split_docs, embedding_model)

# ---------------------5. ë¦¬íŠ¸ë¦¬ë²„ ë° LLM êµ¬ì„± --------------------- # 

class DateSortedRetriever(BaseRetriever, RunnableSerializable):
    base_retriever: BaseRetriever = Field(...)

    def _get_relevant_documents(self, query: str) -> List[Document]:
        docs = self.base_retriever.invoke(query)
        docs_sorted = sorted(
            docs,
            key=lambda d: d.metadata.get("date", "9999-99-99").replace(".", "-")
        )
        return docs_sorted

# ê¸°ë³¸ FAISS ë¦¬íŠ¸ë¦¬ë²„ ì„¤ì •
base_vector_retriever = db.as_retriever(
    search_type="similarity",  # âœ… ì ìˆ˜ í•„í„° ì—†ì´, ìœ ì‚¬ë„ ìˆœ Top-K ë°©ì‹
    search_kwargs={
        "k": 15  # ê°€ì¥ ìœ ì‚¬í•œ 15ê°œ ë¬¸ì„œë¥¼ ê°€ì ¸ì˜´
    }
)

# MultiQueryRetriever ìƒì„±

llm = ChatOpenAI(model_name="gpt-4o",  temperature=0.0)  
multi_query_retriever = MultiQueryRetriever.from_llm(
    retriever=base_vector_retriever,
    llm=llm
)
# --------------------- 5-1. MultiQueryRetriever ì„¤ì • ---------------------

# ë‚ ì§œë¦¬íŠ¸ë¦¬ë²„ ìƒì„±
sorted_retriever = DateSortedRetriever(base_retriever=multi_query_retriever)

# -------# --------------------- 6. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜ ë° QA ì²´ì¸ êµ¬ì„± --------------------- #

prompt_template = PromptTemplate.from_template("""
                                               
ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ” 'ì¹´ë´‡'ì´ì—ìš”.  
CBAM(íƒ„ì†Œêµ­ê²½ì¡°ì •ì œë„) ëŒ€ì‘ í”Œë«í¼ì„ ì§ì ‘ ê°œë°œí–ˆê³ , ì§€ê¸ˆì€ ì´ í”Œë«í¼ê³¼ ê´€ë ¨ëœ ë‚´ìš©ì„ ì•ˆë‚´í•´ë“œë¦¬ê³  ìˆì–´ìš”.

ì œê°€ ì°¸ê³ í•˜ëŠ” ë¬¸ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì„œë¡œ ë‹¤ë¥¸ ì—­í• ì„ í•´ìš”:
                            
1. **í”Œë«í¼ ë°˜ì˜ ì‚¬í•­ ì •ë¦¬ ë¬¸ì„œ**  
   ğŸ‘‰ í”Œë«í¼ì´ ì‹¤ì œë¡œ ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ êµ¬í˜„ë˜ì—ˆëŠ”ì§€ë¥¼ ì„¤ëª…í•˜ëŠ” ë¬¸ì„œì˜ˆìš”.  
   ğŸ‘‰ 'ì›ë˜ëŠ” ì´ë ‡ê²Œ í•´ì•¼ í•˜ëŠ”ë°, ìš°ë¦¬ í”Œë«í¼ì—ì„œëŠ” ì´ë ‡ê²Œ êµ¬í˜„í–ˆì–´ìš”'ì²˜ëŸ¼ ë¹„êµ ì¤‘ì‹¬ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆì–´ìš”.

2. **EU íƒ„ì†Œêµ­ê²½ì œë„ ì „í™˜ê¸°ê°„ ì´í–‰ ê°€ì´ë“œë¼ì¸**  
   ğŸ‘‰ ì œë„ì˜ ê¸°ë³¸ì ì¸ ì ˆì°¨ì™€ ë°©ì‹ì´ ì •ë¦¬ëœ ê³µì‹ ê°€ì´ë“œì˜ˆìš”.

3. **ì•Œê¸°ì‰½ê²Œ í’€ì–´ì“´ CBAM í•´ì„¤ì„œ**  
   ğŸ‘‰ ì œë„ ì „ì²´ì˜ ê°œë…ê³¼ ìš©ì–´ë¥¼ ì‰½ê²Œ ì„¤ëª…í•œ ìë£Œì˜ˆìš”.

---

ğŸ“Œ **ë‹µë³€ ê¸°ì¤€ì€ ì•„ë˜ì™€ ê°™ì•„ìš”:**

- â— ì§ˆë¬¸ì´ ì œë„ ì „ë°˜ì— ëŒ€í•œ ê°œë…ì„ ë¬»ëŠ” ê²½ìš°ì—ëŠ” **ê°€ì´ë“œë¼ì¸ì´ë‚˜ í•´ì„¤ì„œ**ë¥¼ ì°¸ê³ í•´ì„œ ê°œë…ì„ ì„¤ëª…í• ê²Œìš”.
- â— ì§ˆë¬¸ì´ 'ìš°ë¦¬ í”Œë«í¼ì—ì„œ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?'ì²˜ëŸ¼ êµ¬í˜„ ë°©ì‹ì„ ë¬»ëŠ” ê²½ìš°ì—ëŠ” **í”Œë«í¼ ë°˜ì˜ ì‚¬í•­ ì •ë¦¬ ë¬¸ì„œ**ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…ë“œë¦´ê²Œìš”.
- â— ì„œë¡œ ë‹¤ë¥¸ ë¬¸ì„œ ê°„ ë‚´ìš©ì´ ìƒì´í•  ê²½ìš°, **í”Œë«í¼ êµ¬í˜„ ê¸°ì¤€ì„ ìš°ì„ ** ë”°ë¥´ë˜, í•„ìš”í•˜ë©´ ì°¨ì´ì ë„ í•¨ê»˜ ì•Œë ¤ë“œë¦´ê²Œìš”.
- âŒ ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ë‹µë³€ë“œë¦´ ìˆ˜ ì—†ìœ¼ë©°, ì´ ê²½ìš° ì´ë ‡ê²Œ ì•ˆë‚´í• ê²Œìš”: **"ë¬¸ì„œì—ì„œ í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."**
- ëª¨ë“  ë‹µë³€ì€ 150ì ë‚´ì™¸ë¡œ ì‘ì„±í•´ì¤˜  
ì €ëŠ” ì‹¤ë¬´ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ, ì§ˆë¬¸ì˜ ë§¥ë½ì— ë”°ë¼ ê°œë…ê³¼ í”Œë«í¼ êµ¬í˜„ì„ êµ¬ë¶„í•´ì„œ ì„¤ëª…í•´ë“œë¦´ ìˆ˜ ìˆì–´ìš”.  
ê¶ê¸ˆí•œ ì ì´ ìˆë‹¤ë©´ ì–¸ì œë“ ì§€ í¸í•˜ê²Œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”!


ë¬¸ì„œ:
{context}

ì§ˆë¬¸:
{question}
""")

llm = ChatOpenAI(model_name="gpt-4o", temperature=0.0)

qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=sorted_retriever,
    chain_type="stuff",
    chain_type_kwargs={"prompt": prompt_template},
    return_source_documents=True
)
# ---------------------7. íˆìŠ¤í† ë¦¬ ê¸°ë°˜ ì±—ë´‡ í´ë˜ìŠ¤ ì •ì˜ ---------------------(ì‹¤ì œ ì„œë¹„ìŠ¤ìš©)
class CBAMChatbot:
    def __init__(self, qa_chain):
        self.qa_chain = qa_chain
        self.history = []

    def ask(self, user_query: str):
        result = self.qa_chain.invoke({"query": user_query})
        answer = result["result"]
        sources = result["source_documents"]
        self.history.append((user_query, answer))
        return {
            "answer": answer,
            "sources": [
                {
                    "date": doc.metadata.get("date", "N/A"),
                    "preview": doc.page_content[:]
                }
                for doc in sources
            ]
        }

chatbot = CBAMChatbot(qa_chain)

# --------------------- 7. ì§ˆë¬¸ ë¡œë”© ---------------------
import pandas as pd
question_df = pd.read_excel("Q-list_í‰ê°€ìš©ìµœì¢….xlsx", header=2)
questions = [q for q in question_df["Unnamed: 3"].dropna().tolist() if q != "ì§ˆë¬¸"]
# ì •ë‹µ ì¶”ì¶œ (ìˆ«ì, ì´ìƒí•œ ê°’ ì œì™¸)
ground_truths = [
    g for g in question_df["Unnamed: 8"]
    if pd.notna(g)
    and isinstance(g, str)  # ë¬¸ìì—´ë§Œ í—ˆìš©
    and len(g.strip()) > 5  # ë„ˆë¬´ ì§§ì€ ê±´ ì œì™¸
    and g.strip() != "ëŒ€ë‹µ"
]
# --------------------- 8. RAGAS í‰ê°€ìš© ë°ì´í„°ì…‹ ìƒì„± ---------------------
samples = []
for q, g in zip(questions, ground_truths):
    response = chatbot.ask(q)
    samples.append({
        "question": q,
        "answer": response["answer"],
        "contexts": [ctx["preview"] for ctx in response["sources"]],
        "ground_truth": g   # ì—¬ê¸°ì— ì‹¤ì œ ì •ë‹µ ì…ë ¥
    })

ragas_dataset = Dataset.from_list(samples)

# --------------------- 9. RAGAS ì§ˆë¬¸ë³„ í‰ê°€ ì‹¤í–‰ ---------------------
from ragas import SingleTurnSample, EvaluationDataset

for idx, sample_dict in enumerate(samples):
    sample = SingleTurnSample(
        user_input=sample_dict["question"],
        retrieved_contexts=sample_dict["contexts"],
        response=sample_dict["answer"],
        reference=sample_dict["ground_truth"]
    )
    dataset = EvaluationDataset(samples=[sample])
    result = evaluate(
        dataset,
        metrics=[faithfulness, answer_relevancy, context_precision, context_recall]
    )
    print(f"\nğŸ” Q{idx+1}: {sample.user_input}")
    print(f"ğŸ’¬ ì±—ë´‡ ì‘ë‹µ: {sample.response}")
    print(result)

